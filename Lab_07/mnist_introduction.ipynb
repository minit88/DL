{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyORrxXPOxMAlcq+X2eClw44",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minit88/ML-DL/blob/main/Lab_07/mnist_introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Za0miBWSZmCb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.datasets as dsets\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "random.seed(777)\n",
        "torch.manual_seed(777)\n",
        "if device =='cuda':\n",
        "  torch.cuda.manual_seed_all(777)"
      ],
      "metadata": {
        "id": "tgNaGFvCZ0tJ"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_epochs =100\n",
        "batch_size = 100"
      ],
      "metadata": {
        "id": "uYV5lwtWb4yp"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MNIST dataset\n",
        "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
        "                          train=True,\n",
        "                          transform=transforms.ToTensor(),\n",
        "                          download=True)\n",
        "\n",
        "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
        "                         train=False,\n",
        "                         transform=transforms.ToTensor(),\n",
        "                         download=True)"
      ],
      "metadata": {
        "id": "cxROwhlZcBDg"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,batch_size=batch_size,shuffle=True,drop_last=True)"
      ],
      "metadata": {
        "id": "PQFFmUzIeQM-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "linear = torch.nn.Linear(784,10,bias=True).to(device)"
      ],
      "metadata": {
        "id": "VVZn4Rh8e8ym"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define cost/loss & optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
        "optimizer = torch.optim.SGD(linear.parameters(),lr=0.1) "
      ],
      "metadata": {
        "id": "W3ivekbVfIu6"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(training_epochs):\n",
        "    avg_cost = 0\n",
        "    total_batch = len(data_loader)\n",
        "\n",
        "    for X, Y in data_loader:\n",
        "        # reshape input image into [batch_size by 784]\n",
        "        # label is not one-hot encoded\n",
        "        X = X.view(-1, 28 * 28).to(device)\n",
        "        Y = Y.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        hypothesis = linear(X)\n",
        "        cost = criterion(hypothesis, Y)\n",
        "        cost.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        avg_cost += cost / total_batch\n",
        "\n",
        "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
        "\n",
        "print('Learning finished')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrupCB23ffKX",
        "outputId": "13af1c0d-8377-4492-9433-e88ebc303861"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 cost = 0.535150588\n",
            "Epoch: 0002 cost = 0.359577775\n",
            "Epoch: 0003 cost = 0.331264287\n",
            "Epoch: 0004 cost = 0.316404670\n",
            "Epoch: 0005 cost = 0.307107031\n",
            "Epoch: 0006 cost = 0.300456554\n",
            "Epoch: 0007 cost = 0.294933408\n",
            "Epoch: 0008 cost = 0.290956199\n",
            "Epoch: 0009 cost = 0.287074089\n",
            "Epoch: 0010 cost = 0.284515619\n",
            "Epoch: 0011 cost = 0.281914055\n",
            "Epoch: 0012 cost = 0.279526889\n",
            "Epoch: 0013 cost = 0.277636588\n",
            "Epoch: 0014 cost = 0.275874764\n",
            "Epoch: 0015 cost = 0.274422795\n",
            "Epoch: 0016 cost = 0.272883654\n",
            "Epoch: 0017 cost = 0.271629602\n",
            "Epoch: 0018 cost = 0.270609796\n",
            "Epoch: 0019 cost = 0.269295007\n",
            "Epoch: 0020 cost = 0.268277347\n",
            "Epoch: 0021 cost = 0.267255485\n",
            "Epoch: 0022 cost = 0.266613454\n",
            "Epoch: 0023 cost = 0.265661418\n",
            "Epoch: 0024 cost = 0.264922291\n",
            "Epoch: 0025 cost = 0.263888717\n",
            "Epoch: 0026 cost = 0.263269782\n",
            "Epoch: 0027 cost = 0.262586117\n",
            "Epoch: 0028 cost = 0.261751652\n",
            "Epoch: 0029 cost = 0.261135817\n",
            "Epoch: 0030 cost = 0.260536909\n",
            "Epoch: 0031 cost = 0.260275453\n",
            "Epoch: 0032 cost = 0.259709090\n",
            "Epoch: 0033 cost = 0.258947134\n",
            "Epoch: 0034 cost = 0.258617997\n",
            "Epoch: 0035 cost = 0.258048773\n",
            "Epoch: 0036 cost = 0.257542819\n",
            "Epoch: 0037 cost = 0.257166386\n",
            "Epoch: 0038 cost = 0.256698728\n",
            "Epoch: 0039 cost = 0.256314337\n",
            "Epoch: 0040 cost = 0.255765855\n",
            "Epoch: 0041 cost = 0.255531222\n",
            "Epoch: 0042 cost = 0.254914343\n",
            "Epoch: 0043 cost = 0.254686505\n",
            "Epoch: 0044 cost = 0.254367441\n",
            "Epoch: 0045 cost = 0.254017055\n",
            "Epoch: 0046 cost = 0.253749520\n",
            "Epoch: 0047 cost = 0.253456146\n",
            "Epoch: 0048 cost = 0.252950668\n",
            "Epoch: 0049 cost = 0.252728969\n",
            "Epoch: 0050 cost = 0.252436072\n",
            "Epoch: 0051 cost = 0.252046257\n",
            "Epoch: 0052 cost = 0.251570165\n",
            "Epoch: 0053 cost = 0.251367420\n",
            "Epoch: 0054 cost = 0.251246393\n",
            "Epoch: 0055 cost = 0.251039475\n",
            "Epoch: 0056 cost = 0.250813097\n",
            "Epoch: 0057 cost = 0.250424027\n",
            "Epoch: 0058 cost = 0.250028580\n",
            "Epoch: 0059 cost = 0.250024080\n",
            "Epoch: 0060 cost = 0.249757975\n",
            "Epoch: 0061 cost = 0.249497831\n",
            "Epoch: 0062 cost = 0.249265119\n",
            "Epoch: 0063 cost = 0.248886302\n",
            "Epoch: 0064 cost = 0.248696938\n",
            "Epoch: 0065 cost = 0.248614609\n",
            "Epoch: 0066 cost = 0.248439044\n",
            "Epoch: 0067 cost = 0.248139098\n",
            "Epoch: 0068 cost = 0.247835383\n",
            "Epoch: 0069 cost = 0.247658968\n",
            "Epoch: 0070 cost = 0.247397617\n",
            "Epoch: 0071 cost = 0.247249618\n",
            "Epoch: 0072 cost = 0.247079372\n",
            "Epoch: 0073 cost = 0.246945292\n",
            "Epoch: 0074 cost = 0.246686921\n",
            "Epoch: 0075 cost = 0.246687874\n",
            "Epoch: 0076 cost = 0.246303037\n",
            "Epoch: 0077 cost = 0.246110290\n",
            "Epoch: 0078 cost = 0.246067807\n",
            "Epoch: 0079 cost = 0.245769799\n",
            "Epoch: 0080 cost = 0.245565936\n",
            "Epoch: 0081 cost = 0.245506600\n",
            "Epoch: 0082 cost = 0.245446190\n",
            "Epoch: 0083 cost = 0.245212123\n",
            "Epoch: 0084 cost = 0.244949400\n",
            "Epoch: 0085 cost = 0.244855195\n",
            "Epoch: 0086 cost = 0.244703412\n",
            "Epoch: 0087 cost = 0.244637147\n",
            "Epoch: 0088 cost = 0.244337335\n",
            "Epoch: 0089 cost = 0.244136691\n",
            "Epoch: 0090 cost = 0.244086951\n",
            "Epoch: 0091 cost = 0.243965819\n",
            "Epoch: 0092 cost = 0.243704528\n",
            "Epoch: 0093 cost = 0.243614852\n",
            "Epoch: 0094 cost = 0.243434444\n",
            "Epoch: 0095 cost = 0.243306980\n",
            "Epoch: 0096 cost = 0.243146718\n",
            "Epoch: 0097 cost = 0.243119434\n",
            "Epoch: 0098 cost = 0.243019551\n",
            "Epoch: 0099 cost = 0.242854834\n",
            "Epoch: 0100 cost = 0.242440462\n",
            "Learning finished\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model using test sets\n",
        "with torch.no_grad():\n",
        "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
        "    Y_test = mnist_test.test_labels.to(device)\n",
        "\n",
        "    prediction = linear(X_test)\n",
        "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
        "    accuracy = correct_prediction.float().mean()\n",
        "    print('Accuracy:', accuracy.item())\n",
        "\n",
        "    # Get one and predict\n",
        "    r = random.randint(0, len(mnist_test) - 1)\n",
        "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
        "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
        "\n",
        "    print('Label: ', Y_single_data.item())\n",
        "    single_prediction = linear(X_single_data)\n",
        "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
        "\n",
        "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
        "    plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "2W-mXyQxguHn",
        "outputId": "74992b64-ac68-49e9-d3d9-de6fca31803f"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8779000043869019\n",
            "Label:  8\n",
            "Prediction:  3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}